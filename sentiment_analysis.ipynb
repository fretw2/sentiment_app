{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Deep Learning Model\n",
    "\n",
    "We will create a simple deep learning model for sentiment analysis. The dataset is from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECK VERSIONS OF THE FOLLOWING:\n",
    " -  Python (some issues with v3.9 and above, no problems with v3.7 or v3.8)\n",
    " - Tensorflow (most ok, here we use v2.0.0)\n",
    " - Keras (testing v2.3.1, best v2.4.3)\n",
    " - NumPy (breaking issues above v1.19.5, using v1.19.2)\n",
    " - h5py (v2.10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "h5py.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # to read .csv files (data)\n",
    "\n",
    "# using Tensorflow for modeling\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "\n",
    "# model validation using train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re    # to perform reg-ex on textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'candidate', 'candidate_confidence', 'relevant_yn',\n",
       "       'relevant_yn_confidence', 'sentiment', 'sentiment_confidence',\n",
       "       'subject_matter', 'subject_matter_confidence', 'candidate_gold', 'name',\n",
       "       'relevant_yn_gold', 'retweet_count', 'sentiment_gold',\n",
       "       'subject_matter_gold', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_id', 'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Sentiment.csv') # use local path of data file\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prune the columns that we don't need\n",
    "\n",
    "data = data[['text', 'sentiment']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted characters via Regex\n",
    "\n",
    "def clean_data(text):    # helper function\n",
    "    text = text.lower()\n",
    "    new_text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
    "    new_text = re.sub('rt', '', new_text)\n",
    "    return new_text\n",
    "\n",
    "data['text'] = data['text'].apply(clean_data) # clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nancyleegrahn how did everyone feel about the...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scottwalker didnt catch the full gopdebate la...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tjmshow no mention of tamir rice and the gopd...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robgeorge that carly fiorina is trending  hou...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>danscavino gopdebate w realdonaldtrump delive...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0   nancyleegrahn how did everyone feel about the...   Neutral\n",
       "1   scottwalker didnt catch the full gopdebate la...  Positive\n",
       "2   tjmshow no mention of tamir rice and the gopd...   Neutral\n",
       "3   robgeorge that carly fiorina is trending  hou...  Positive\n",
       "4   danscavino gopdebate w realdonaldtrump delive...  Positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_feats = 2000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_feats, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "# tokenize dataset\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "# pad sequences\n",
    "X = pad_sequences(X, 28)\n",
    "\n",
    "# convert categorical data to indicator variables (dummies)\n",
    "Y = pd.get_dummies(data['sentiment']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train-test datasets (for model validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data 80:20 (80% training, 20% testing)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a simple deep learning model\n",
    "\n",
    "This example is using an embedding layer and some LSTM layers with dropout. We are also using categorical cross-entropy loss, and the optimizer function we are using is Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "# embedding layer\n",
    "model.add(Embedding(max_feats, embed_dim, input_length=X.shape[1]))\n",
    "# dropout\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "# LSTM layers\n",
    "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(LSTM(128, recurrent_dropout=0.2))\n",
    "# Dense with softmax activation\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11096 samples, validate on 2775 samples\n",
      "Epoch 1/10\n",
      "11096/11096 [==============================] - 36s 3ms/sample - loss: 0.9520 - accuracy: 0.5967 - val_loss: 0.8973 - val_accuracy: 0.6054\n",
      "Epoch 2/10\n",
      "11096/11096 [==============================] - 22s 2ms/sample - loss: 0.8465 - accuracy: 0.6218 - val_loss: 0.8067 - val_accuracy: 0.6468\n",
      "Epoch 3/10\n",
      "11096/11096 [==============================] - 23s 2ms/sample - loss: 0.7567 - accuracy: 0.6718 - val_loss: 0.7549 - val_accuracy: 0.6659\n",
      "Epoch 4/10\n",
      "11096/11096 [==============================] - 25s 2ms/sample - loss: 0.6939 - accuracy: 0.6995 - val_loss: 0.7353 - val_accuracy: 0.6850\n",
      "Epoch 5/10\n",
      "11096/11096 [==============================] - 25s 2ms/sample - loss: 0.6486 - accuracy: 0.7213 - val_loss: 0.7282 - val_accuracy: 0.6868\n",
      "Epoch 6/10\n",
      "11096/11096 [==============================] - 27s 2ms/sample - loss: 0.6203 - accuracy: 0.7335 - val_loss: 0.7320 - val_accuracy: 0.6883\n",
      "Epoch 7/10\n",
      "11096/11096 [==============================] - 27s 2ms/sample - loss: 0.5963 - accuracy: 0.7441 - val_loss: 0.7403 - val_accuracy: 0.6818\n",
      "Epoch 8/10\n",
      "11096/11096 [==============================] - 27s 2ms/sample - loss: 0.5802 - accuracy: 0.7504 - val_loss: 0.7481 - val_accuracy: 0.6807\n",
      "Epoch 9/10\n",
      "11096/11096 [==============================] - 28s 3ms/sample - loss: 0.5700 - accuracy: 0.7542 - val_loss: 0.7538 - val_accuracy: 0.6724\n",
      "Epoch 10/10\n",
      "11096/11096 [==============================] - 29s 3ms/sample - loss: 0.5590 - accuracy: 0.7656 - val_loss: 0.7708 - val_accuracy: 0.6717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f6fdaf3548>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, batch_size=512, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model\n",
    "\n",
    "Here we are saving the model in 'hdf5' format (.h5 file type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('py_sentiment.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the REST API\n",
    "\n",
    "See file **sentiment_app.py**. We are making a REST API using FAST API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the app\n",
    "\n",
    "The created app, within the Python program **sentiment_app.py** can be run using the following **uvicorn** command:\n",
    "\n",
    "```$ uvicorn sentiment_app:app --reload```\n",
    "\n",
    "We use the above command formatting because\n",
    " -  sentiment_app refers to the name of the Python program that define the app, in this case **sentiment_app.py**\n",
    " -  app refers to the name of the variable defined in **sentiment_app.py** of which we instantiated the app\n",
    "\n",
    "       ```app = FastAPI()```\n",
    "\n",
    "    (*see line 11 in* ***sentiment_app.py***)\n",
    "    \n",
    "The app should take you to the user page at the following address:\n",
    "\n",
    "```http://127.0.0.1:8000/docs```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the app can be tested with FastAPI at the /docs route:\n",
    "\n",
    "```http://127.0.0.1:8000/docs```\n",
    "\n",
    "(*the prettier app output*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for app deployment\n",
    "\n",
    "To deploy a version of the app on Heroku, we need the following files:\n",
    " - **runtime.txt**, which version of Python is suitable. In this case **runtime.txt** should read\n",
    "\n",
    " ```python-3.7.6```, or ```python-VERSION```\n",
    "\n",
    "\n",
    " - **Procfile**, of file-type no extension (.). It should simply read\n",
    " \n",
    " ```web: uvicorn sentiment_app:app --host=0.0.0.0 --port=${PORT:-5000}```\n",
    "\n",
    "  - We use the above values because we will run the server on 0.0.0.0 and the port on Heroku should be 5000.\n",
    "  - The **Procfile** can be created on Visual Studio Code or other IDEs that allow for file creation of the type *no extension*.\n",
    " - **requirements.txt**, a text file of all the libraries used in the project. Our file reads\n",
    " \n",
    " ```pandas\n",
    "sklearn\n",
    "tensorflow==2.0.0\n",
    "h5py==2.10.0\n",
    "fastapi\n",
    "uvicorn\n",
    "python-multipart\n",
    " ```\n",
    " \n",
    " - **gitignore.txt**, a file that stores the name of the files that will not be used for Heroku. Ours is as follows:\n",
    " \n",
    " ```???\n",
    " __pycache__\n",
    " model.py\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying on Github\n",
    "\n",
    "Create a new Git repository to host the project files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the project directory, do the following (on command line)\n",
    "\n",
    "```$ git init```\n",
    "\n",
    "This command should return a response like below\n",
    "\n",
    "```Initialized empty Git repository in absolute_path_of_project_directory/.git/```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
